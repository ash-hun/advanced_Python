{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with nn.Module in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f10440574b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Module\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[1],[2],[3]])\n",
    "y_train = torch.FloatTensor([[2],[4],[6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dim = 1, output_dim=1\n",
    "model = nn.Linear(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[0.5153]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4414], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/2001 Cost: 13.103541\n",
      "Epoch  100/2001 Cost: 0.002791\n",
      "Epoch  200/2001 Cost: 0.001724\n",
      "Epoch  300/2001 Cost: 0.001066\n",
      "Epoch  400/2001 Cost: 0.000658\n",
      "Epoch  500/2001 Cost: 0.000407\n",
      "Epoch  600/2001 Cost: 0.000251\n",
      "Epoch  700/2001 Cost: 0.000155\n",
      "Epoch  800/2001 Cost: 0.000096\n",
      "Epoch  900/2001 Cost: 0.000059\n",
      "Epoch 1000/2001 Cost: 0.000037\n",
      "Epoch 1100/2001 Cost: 0.000023\n",
      "Epoch 1200/2001 Cost: 0.000014\n",
      "Epoch 1300/2001 Cost: 0.000009\n",
      "Epoch 1400/2001 Cost: 0.000005\n",
      "Epoch 1500/2001 Cost: 0.000003\n",
      "Epoch 1600/2001 Cost: 0.000002\n",
      "Epoch 1700/2001 Cost: 0.000001\n",
      "Epoch 1800/2001 Cost: 0.000001\n",
      "Epoch 1900/2001 Cost: 0.000000\n",
      "Epoch 2000/2001 Cost: 0.000000\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 2001\n",
    "for epoch in range(nb_epochs):\n",
    "    prediction = model(x_train)\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch%100==0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(epoch, nb_epochs, cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 후 입력이 4일 때의 예측값 :  tensor([[7.9989]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "new_var = torch.FloatTensor([[4.0]])\n",
    "pred_y = model(new_var)\n",
    "print(\"훈련 후 입력이 4일 때의 예측값 : \", pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 문제의 정답은 $$y=2x$$ 이므로 $$y$$값이 8에 가까우면 가중치와 편향이 어느정도 최적화가 되었다고 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[1.9994]], requires_grad=True), Parameter containing:\n",
      "tensor([0.0014], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariable Linear Regression with nn.Module in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터\n",
    "xx_train = torch.FloatTensor([[73, 80, 75],\n",
    "                             [93, 88, 93],\n",
    "                             [89, 91, 90],\n",
    "                             [96, 98, 100],\n",
    "                             [73, 66, 70]])\n",
    "yy_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmodel = nn.Linear(3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.0968, -0.2490, -0.1850]], requires_grad=True), Parameter containing:\n",
      "tensor([0.0276], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(mmodel.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(mmodel.parameters(), lr=1e-5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/10000 Cost: 0.256865\n",
      "Epoch  100/10000 Cost: 0.256211\n",
      "Epoch  200/10000 Cost: 0.255569\n",
      "Epoch  300/10000 Cost: 0.254935\n",
      "Epoch  400/10000 Cost: 0.254335\n",
      "Epoch  500/10000 Cost: 0.253728\n",
      "Epoch  600/10000 Cost: 0.253141\n",
      "Epoch  700/10000 Cost: 0.252554\n",
      "Epoch  800/10000 Cost: 0.251995\n",
      "Epoch  900/10000 Cost: 0.251436\n",
      "Epoch 1000/10000 Cost: 0.250886\n",
      "Epoch 1100/10000 Cost: 0.250344\n",
      "Epoch 1200/10000 Cost: 0.249821\n",
      "Epoch 1300/10000 Cost: 0.249289\n",
      "Epoch 1400/10000 Cost: 0.248781\n",
      "Epoch 1500/10000 Cost: 0.248275\n",
      "Epoch 1600/10000 Cost: 0.247781\n",
      "Epoch 1700/10000 Cost: 0.247292\n",
      "Epoch 1800/10000 Cost: 0.246805\n",
      "Epoch 1900/10000 Cost: 0.246337\n",
      "Epoch 2000/10000 Cost: 0.245863\n",
      "Epoch 2100/10000 Cost: 0.245404\n",
      "Epoch 2200/10000 Cost: 0.244945\n",
      "Epoch 2300/10000 Cost: 0.244490\n",
      "Epoch 2400/10000 Cost: 0.244046\n",
      "Epoch 2500/10000 Cost: 0.243612\n",
      "Epoch 2600/10000 Cost: 0.243166\n",
      "Epoch 2700/10000 Cost: 0.242744\n",
      "Epoch 2800/10000 Cost: 0.242320\n",
      "Epoch 2900/10000 Cost: 0.241889\n",
      "Epoch 3000/10000 Cost: 0.241475\n",
      "Epoch 3100/10000 Cost: 0.241068\n",
      "Epoch 3200/10000 Cost: 0.240656\n",
      "Epoch 3300/10000 Cost: 0.240253\n",
      "Epoch 3400/10000 Cost: 0.239850\n",
      "Epoch 3500/10000 Cost: 0.239455\n",
      "Epoch 3600/10000 Cost: 0.239054\n",
      "Epoch 3700/10000 Cost: 0.238675\n",
      "Epoch 3800/10000 Cost: 0.238286\n",
      "Epoch 3900/10000 Cost: 0.237910\n",
      "Epoch 4000/10000 Cost: 0.237523\n",
      "Epoch 4100/10000 Cost: 0.237158\n",
      "Epoch 4200/10000 Cost: 0.236777\n",
      "Epoch 4300/10000 Cost: 0.236410\n",
      "Epoch 4400/10000 Cost: 0.236043\n",
      "Epoch 4500/10000 Cost: 0.235675\n",
      "Epoch 4600/10000 Cost: 0.235316\n",
      "Epoch 4700/10000 Cost: 0.234951\n",
      "Epoch 4800/10000 Cost: 0.234599\n",
      "Epoch 4900/10000 Cost: 0.234248\n",
      "Epoch 5000/10000 Cost: 0.233893\n",
      "Epoch 5100/10000 Cost: 0.233548\n",
      "Epoch 5200/10000 Cost: 0.233198\n",
      "Epoch 5300/10000 Cost: 0.232860\n",
      "Epoch 5400/10000 Cost: 0.232522\n",
      "Epoch 5500/10000 Cost: 0.232181\n",
      "Epoch 5600/10000 Cost: 0.231844\n",
      "Epoch 5700/10000 Cost: 0.231498\n",
      "Epoch 5800/10000 Cost: 0.231166\n",
      "Epoch 5900/10000 Cost: 0.230845\n",
      "Epoch 6000/10000 Cost: 0.230516\n",
      "Epoch 6100/10000 Cost: 0.230193\n",
      "Epoch 6200/10000 Cost: 0.229869\n",
      "Epoch 6300/10000 Cost: 0.229548\n",
      "Epoch 6400/10000 Cost: 0.229223\n",
      "Epoch 6500/10000 Cost: 0.228902\n",
      "Epoch 6600/10000 Cost: 0.228582\n",
      "Epoch 6700/10000 Cost: 0.228274\n",
      "Epoch 6800/10000 Cost: 0.227963\n",
      "Epoch 6900/10000 Cost: 0.227653\n",
      "Epoch 7000/10000 Cost: 0.227341\n",
      "Epoch 7100/10000 Cost: 0.227033\n",
      "Epoch 7200/10000 Cost: 0.226728\n",
      "Epoch 7300/10000 Cost: 0.226421\n",
      "Epoch 7400/10000 Cost: 0.226122\n",
      "Epoch 7500/10000 Cost: 0.225820\n",
      "Epoch 7600/10000 Cost: 0.225523\n",
      "Epoch 7700/10000 Cost: 0.225226\n",
      "Epoch 7800/10000 Cost: 0.224930\n",
      "Epoch 7900/10000 Cost: 0.224634\n",
      "Epoch 8000/10000 Cost: 0.224341\n",
      "Epoch 8100/10000 Cost: 0.224051\n",
      "Epoch 8200/10000 Cost: 0.223758\n",
      "Epoch 8300/10000 Cost: 0.223474\n",
      "Epoch 8400/10000 Cost: 0.223187\n",
      "Epoch 8500/10000 Cost: 0.222907\n",
      "Epoch 8600/10000 Cost: 0.222621\n",
      "Epoch 8700/10000 Cost: 0.222334\n",
      "Epoch 8800/10000 Cost: 0.222057\n",
      "Epoch 8900/10000 Cost: 0.221778\n",
      "Epoch 9000/10000 Cost: 0.221500\n",
      "Epoch 9100/10000 Cost: 0.221222\n",
      "Epoch 9200/10000 Cost: 0.220951\n",
      "Epoch 9300/10000 Cost: 0.220677\n",
      "Epoch 9400/10000 Cost: 0.220407\n",
      "Epoch 9500/10000 Cost: 0.220137\n",
      "Epoch 9600/10000 Cost: 0.219868\n",
      "Epoch 9700/10000 Cost: 0.219603\n",
      "Epoch 9800/10000 Cost: 0.219326\n",
      "Epoch 9900/10000 Cost: 0.219065\n",
      "Epoch 10000/10000 Cost: 0.218804\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 10000\n",
    "for epoch in range(nb_epochs+1):\n",
    "\n",
    "    # H(x) 계산\n",
    "    prediction = mmodel(xx_train)\n",
    "    # model(x_train)은 model.forward(x_train)와 동일함.\n",
    "\n",
    "    # cost 계산\n",
    "    cost = F.mse_loss(prediction, yy_train) # <== 파이토치에서 제공하는 평균 제곱 오차 함수\n",
    "\n",
    "    # cost로 H(x) 개선하는 부분\n",
    "    # gradient를 0으로 초기화\n",
    "    optimizer.zero_grad()\n",
    "    # 비용 함수를 미분하여 gradient 계산\n",
    "    cost.backward()\n",
    "    # W와 b를 업데이트\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "    # 100번마다 로그 출력\n",
    "      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "          epoch, nb_epochs, cost.item()\n",
    "      ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 후 입력이 73, 80, 75일 때의 예측값 : tensor([[151.3319]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 임의의 입력 [73, 80, 75]를 선언\n",
    "new_var =  torch.FloatTensor([[73, 80, 75]]) \n",
    "# 입력한 값 [73, 80, 75]에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
    "pred_y = mmodel(new_var) \n",
    "print(\"훈련 후 입력이 73, 80, 75일 때의 예측값 :\", pred_y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사실 3개의 값 73, 80, 75는 훈련 데이터로 사용되었던 값입니다.  \n",
    "당시 y의 값은 152였는데, 현재 예측값이 151이 나온 것으로 보아 어느정도는 3개의 w와 b의 값이 최적화 된것으로 보입니다. 이제 학습 후의 3개의 w와 b의 값을 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[0.8541, 0.8475, 0.3096]], requires_grad=True), Parameter containing:\n",
      "tensor([0.3568], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa6f37d631bf365f04fc4bc3180adfc9b3dd8f2856279e1e747cdbbf0e44bcd9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
